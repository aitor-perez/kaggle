{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 04 Neural Networks with keras - 02 Simple approach\n",
    "\n",
    "In this notebook we implement an approach based on neural networks, using the library **keras** from **tensorflow** to predict whether the tweets refer to a real disaster or not. We establish a simple, fixed architecture with just one dense layer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loading data\n",
    "\n",
    "We start by importing the packages we are going to use and loading the datasets:"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from keras.layers import TextVectorization\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train_data = pd.read_csv(\"../../data/train.csv\")\n",
    "test_data = pd.read_csv(\"../../data/test.csv\")\n",
    "\n",
    "train_data['text'].replace('http:\\/\\/\\S*', 'urltoken', regex=True, inplace=True)\n",
    "test_data['text'].replace('http:\\/\\/\\S*', 'urltoken', regex=True, inplace=True)\n",
    "\n",
    "train_text, train_label = np.array(train_data['text']), np.array(train_data['target'])\n",
    "test_text = test_data['text']\n",
    "\n",
    "print(train_text.shape)\n",
    "print(train_label.shape)\n",
    "print(test_text.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2021-09-13T15:08:54.835726Z",
     "iopub.execute_input": "2021-09-13T15:08:54.836899Z",
     "iopub.status.idle": "2021-09-13T15:08:54.893333Z",
     "shell.execute_reply.started": "2021-09-13T15:08:54.836857Z",
     "shell.execute_reply": "2021-09-13T15:08:54.89268Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613,)\n",
      "(7613,)\n",
      "(3263,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We explore the training data. There average tweet has 15 words, and the longest one has 31:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "count    7613.000000\nmean       14.903586\nstd         5.732604\nmin         1.000000\n25%        11.000000\n50%        15.000000\n75%        19.000000\nmax        31.000000\ndtype: float64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word counts\n",
    "pd.Series(np.array([len(text.split()) for text in train_text])).describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are 27736 unique words in all the tweets:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "27736"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique tokens among all tweets\n",
    "len(np.unique(np.array(' '.join(train_text).split())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model building\n",
    "\n",
    "The following function will create and return a model with a fixed layer architecture whose hyperparameters are defined above.\n",
    "\n",
    "We start with a **TextVectorization** layer with usual standardization, followed by an **Embedding** layer. We then compose with a **Dense** layer and perform **GlobalMaxPooling1D**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "max_features = 30000\n",
    "sequence_length = 32\n",
    "\n",
    "embedding_dim = 4\n",
    "\n",
    "def build_model():\n",
    "    # Inputs are text strings, then we vectorize them\n",
    "    inputs = keras.Input(shape=(1,), dtype=tf.string, name='text')\n",
    "\n",
    "    vectorizer = TextVectorization(\n",
    "        standardize='lower_and_strip_punctuation',\n",
    "        max_tokens=max_features,\n",
    "        output_mode=\"int\",\n",
    "        output_sequence_length=sequence_length,\n",
    "    )\n",
    "    vectorizer.adapt(train_text)\n",
    "    x = vectorizer(inputs)\n",
    "\n",
    "    # We use Embedding to map the vectorized text onto a space of dimension embedding_dim\n",
    "    x = Embedding(max_features + 1, embedding_dim)(x)\n",
    "\n",
    "    # Dense layer\n",
    "    x = Dense(embedding_dim, activation='relu')(x)\n",
    "\n",
    "    # GlobalMaxPooling\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation='sigmoid', name='predictions')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model training\n",
    "\n",
    "We are now ready to train the model. We start by creating an instance and printing a summary:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 17:25:48.131454: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-23 17:25:48.324508: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text (InputLayer)            [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 32, 4)             120004    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32, 4)             20        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 120,029\n",
      "Trainable params: 120,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use 10-fold cross-validation and train for 10 epochs:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "> Fold 1\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "215/215 - 2s - loss: 0.6723 - accuracy: 0.5736 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00\n",
      "Epoch 2/10\n",
      "215/215 - 1s - loss: 0.6198 - accuracy: 0.6872 - precision_1: 0.7763 - recall_1: 0.3742\n",
      "Epoch 3/10\n",
      "215/215 - 1s - loss: 0.5575 - accuracy: 0.7425 - precision_1: 0.7436 - recall_1: 0.6046\n",
      "Epoch 4/10\n",
      "215/215 - 1s - loss: 0.5010 - accuracy: 0.7786 - precision_1: 0.7835 - recall_1: 0.6642\n",
      "Epoch 5/10\n",
      "215/215 - 1s - loss: 0.4490 - accuracy: 0.8161 - precision_1: 0.8377 - recall_1: 0.7052\n",
      "Epoch 6/10\n",
      "215/215 - 1s - loss: 0.3992 - accuracy: 0.8483 - precision_1: 0.8810 - recall_1: 0.7450\n",
      "Epoch 7/10\n",
      "215/215 - 1s - loss: 0.3541 - accuracy: 0.8683 - precision_1: 0.9011 - recall_1: 0.7764\n",
      "Epoch 8/10\n",
      "215/215 - 1s - loss: 0.3152 - accuracy: 0.8857 - precision_1: 0.9186 - recall_1: 0.8031\n",
      "Epoch 9/10\n",
      "215/215 - 1s - loss: 0.2817 - accuracy: 0.8962 - precision_1: 0.9240 - recall_1: 0.8244\n",
      "Epoch 10/10\n",
      "215/215 - 1s - loss: 0.2531 - accuracy: 0.9056 - precision_1: 0.9297 - recall_1: 0.8422\n",
      "215/215 - 1s - loss: 0.2280 - accuracy: 0.9197 - precision_1: 0.9325 - recall_1: 0.8750\n",
      "24/24 - 0s - loss: 0.5972 - accuracy: 0.7178 - precision_1: 0.6991 - recall_1: 0.6771\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "215/215 - 2s - loss: 0.6828 - accuracy: 0.6266 - precision_2: 0.5497 - recall_2: 0.7231\n",
      "Epoch 2/10\n",
      "215/215 - 1s - loss: 0.6371 - accuracy: 0.6862 - precision_2: 0.6081 - recall_2: 0.7581\n",
      "Epoch 3/10\n",
      "215/215 - 1s - loss: 0.5683 - accuracy: 0.8119 - precision_2: 0.8034 - recall_2: 0.7441\n",
      "Epoch 4/10\n",
      "215/215 - 1s - loss: 0.5033 - accuracy: 0.8492 - precision_2: 0.8448 - recall_2: 0.7951\n",
      "Epoch 5/10\n",
      "215/215 - 1s - loss: 0.4508 - accuracy: 0.8721 - precision_2: 0.8572 - recall_2: 0.8427\n",
      "Epoch 6/10\n",
      "215/215 - 1s - loss: 0.4022 - accuracy: 0.8859 - precision_2: 0.8657 - recall_2: 0.8692\n",
      "Epoch 7/10\n",
      "215/215 - 1s - loss: 0.3625 - accuracy: 0.8946 - precision_2: 0.8676 - recall_2: 0.8906\n",
      "Epoch 8/10\n",
      "215/215 - 1s - loss: 0.3300 - accuracy: 0.9012 - precision_2: 0.8710 - recall_2: 0.9038\n",
      "Epoch 9/10\n",
      "215/215 - 1s - loss: 0.3042 - accuracy: 0.9035 - precision_2: 0.8776 - recall_2: 0.9011\n",
      "Epoch 10/10\n",
      "215/215 - 1s - loss: 0.2841 - accuracy: 0.9063 - precision_2: 0.8806 - recall_2: 0.9045\n",
      "215/215 - 1s - loss: 0.2663 - accuracy: 0.9146 - precision_2: 0.8972 - recall_2: 0.9049\n",
      "24/24 - 0s - loss: 0.6298 - accuracy: 0.7362 - precision_2: 0.7182 - recall_2: 0.6372\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "215/215 - 2s - loss: 0.6762 - accuracy: 0.5818 - precision_3: 0.6462 - recall_3: 0.0608\n",
      "Epoch 2/10\n",
      "215/215 - 1s - loss: 0.6246 - accuracy: 0.6866 - precision_3: 0.7662 - recall_3: 0.3904\n",
      "Epoch 3/10\n",
      "215/215 - 1s - loss: 0.5449 - accuracy: 0.7749 - precision_3: 0.7875 - recall_3: 0.6527\n",
      "Epoch 4/10\n",
      "215/215 - 1s - loss: 0.4681 - accuracy: 0.8194 - precision_3: 0.8250 - recall_3: 0.7363\n",
      "Epoch 5/10\n",
      "215/215 - 1s - loss: 0.3995 - accuracy: 0.8521 - precision_3: 0.8665 - recall_3: 0.7756\n",
      "Epoch 6/10\n",
      "215/215 - 1s - loss: 0.3413 - accuracy: 0.8749 - precision_3: 0.8949 - recall_3: 0.8035\n",
      "Epoch 7/10\n",
      "215/215 - 1s - loss: 0.2929 - accuracy: 0.8956 - precision_3: 0.9070 - recall_3: 0.8439\n",
      "Epoch 8/10\n",
      "215/215 - 1s - loss: 0.2530 - accuracy: 0.9129 - precision_3: 0.9217 - recall_3: 0.8714\n",
      "Epoch 9/10\n",
      "215/215 - 1s - loss: 0.2213 - accuracy: 0.9231 - precision_3: 0.9287 - recall_3: 0.8893\n",
      "Epoch 10/10\n",
      "215/215 - 1s - loss: 0.1957 - accuracy: 0.9314 - precision_3: 0.9362 - recall_3: 0.9019\n",
      "215/215 - 1s - loss: 0.1706 - accuracy: 0.9458 - precision_3: 0.9541 - recall_3: 0.9182\n",
      "24/24 - 0s - loss: 0.5246 - accuracy: 0.7612 - precision_3: 0.7256 - recall_3: 0.7077\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "215/215 - 2s - loss: 0.6761 - accuracy: 0.5730 - precision_4: 0.7600 - recall_4: 0.0065\n",
      "Epoch 2/10\n",
      "215/215 - 1s - loss: 0.6124 - accuracy: 0.7040 - precision_4: 0.8523 - recall_4: 0.3750\n",
      "Epoch 3/10\n",
      "215/215 - 1s - loss: 0.5143 - accuracy: 0.7859 - precision_4: 0.8145 - recall_4: 0.6485\n",
      "Epoch 4/10\n",
      "215/215 - 1s - loss: 0.4306 - accuracy: 0.8345 - precision_4: 0.8600 - recall_4: 0.7336\n",
      "Epoch 5/10\n",
      "215/215 - 1s - loss: 0.3657 - accuracy: 0.8641 - precision_4: 0.8876 - recall_4: 0.7822\n",
      "Epoch 6/10\n",
      "215/215 - 1s - loss: 0.3140 - accuracy: 0.8856 - precision_4: 0.9089 - recall_4: 0.8149\n",
      "Epoch 7/10\n",
      "215/215 - 1s - loss: 0.2729 - accuracy: 0.9005 - precision_4: 0.9194 - recall_4: 0.8418\n",
      "Epoch 8/10\n",
      "215/215 - 1s - loss: 0.2387 - accuracy: 0.9140 - precision_4: 0.9307 - recall_4: 0.8639\n",
      "Epoch 9/10\n",
      "215/215 - 1s - loss: 0.2093 - accuracy: 0.9256 - precision_4: 0.9402 - recall_4: 0.8826\n",
      "Epoch 10/10\n",
      "215/215 - 1s - loss: 0.1846 - accuracy: 0.9356 - precision_4: 0.9464 - recall_4: 0.9010\n",
      "215/215 - 1s - loss: 0.1600 - accuracy: 0.9459 - precision_4: 0.9521 - recall_4: 0.9200\n",
      "24/24 - 0s - loss: 0.4711 - accuracy: 0.7898 - precision_4: 0.7739 - recall_4: 0.7319\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "215/215 - 2s - loss: 0.6764 - accuracy: 0.5698 - precision_5: 1.0000 - recall_5: 0.0024\n",
      "Epoch 2/10\n",
      "215/215 - 1s - loss: 0.6050 - accuracy: 0.6989 - precision_5: 0.8780 - recall_5: 0.3506\n",
      "Epoch 3/10\n",
      "215/215 - 1s - loss: 0.4993 - accuracy: 0.8257 - precision_5: 0.8649 - recall_5: 0.7063\n",
      "Epoch 4/10\n",
      "215/215 - 1s - loss: 0.4117 - accuracy: 0.8571 - precision_5: 0.8809 - recall_5: 0.7733\n",
      "Epoch 5/10\n",
      "215/215 - 1s - loss: 0.3462 - accuracy: 0.8746 - precision_5: 0.8970 - recall_5: 0.8014\n",
      "Epoch 6/10\n",
      "215/215 - 1s - loss: 0.2959 - accuracy: 0.8917 - precision_5: 0.9034 - recall_5: 0.8386\n",
      "Epoch 7/10\n",
      "215/215 - 1s - loss: 0.2533 - accuracy: 0.9110 - precision_5: 0.9198 - recall_5: 0.8694\n",
      "Epoch 8/10\n",
      "215/215 - 1s - loss: 0.2171 - accuracy: 0.9263 - precision_5: 0.9359 - recall_5: 0.8900\n",
      "Epoch 9/10\n",
      "215/215 - 1s - loss: 0.1873 - accuracy: 0.9383 - precision_5: 0.9442 - recall_5: 0.9107\n",
      "Epoch 10/10\n",
      "215/215 - 1s - loss: 0.1633 - accuracy: 0.9483 - precision_5: 0.9565 - recall_5: 0.9222\n",
      "215/215 - 1s - loss: 0.1395 - accuracy: 0.9596 - precision_5: 0.9649 - recall_5: 0.9404\n",
      "24/24 - 0s - loss: 0.5887 - accuracy: 0.7530 - precision_5: 0.7065 - recall_5: 0.6930\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "215/215 - 2s - loss: 0.6727 - accuracy: 0.6013 - precision_6: 0.6038 - recall_6: 0.1947\n",
      "Epoch 2/10\n",
      "215/215 - 1s - loss: 0.6017 - accuracy: 0.7560 - precision_6: 0.7948 - recall_6: 0.5782\n",
      "Epoch 3/10\n",
      "215/215 - 1s - loss: 0.5084 - accuracy: 0.8109 - precision_6: 0.8251 - recall_6: 0.7073\n",
      "Epoch 4/10\n",
      "215/215 - 1s - loss: 0.4345 - accuracy: 0.8469 - precision_6: 0.8671 - recall_6: 0.7579\n",
      "Epoch 5/10\n",
      "215/215 - 1s - loss: 0.3781 - accuracy: 0.8630 - precision_6: 0.8789 - recall_6: 0.7879\n",
      "Epoch 6/10\n",
      "215/215 - 1s - loss: 0.3310 - accuracy: 0.8757 - precision_6: 0.8836 - recall_6: 0.8166\n",
      "Epoch 7/10\n",
      "215/215 - 1s - loss: 0.2900 - accuracy: 0.8917 - precision_6: 0.8881 - recall_6: 0.8542\n",
      "Epoch 8/10\n",
      "215/215 - 1s - loss: 0.2572 - accuracy: 0.9034 - precision_6: 0.8975 - recall_6: 0.8736\n",
      "Epoch 9/10\n",
      "215/215 - 1s - loss: 0.2299 - accuracy: 0.9152 - precision_6: 0.9116 - recall_6: 0.8876\n",
      "Epoch 10/10\n",
      "215/215 - 1s - loss: 0.2082 - accuracy: 0.9228 - precision_6: 0.9207 - recall_6: 0.8965\n",
      "215/215 - 1s - loss: 0.1844 - accuracy: 0.9362 - precision_6: 0.9375 - recall_6: 0.9115\n",
      "24/24 - 0s - loss: 0.5636 - accuracy: 0.7622 - precision_6: 0.7774 - recall_6: 0.6618\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "215/215 - 2s - loss: 0.6790 - accuracy: 0.5661 - precision_7: 0.2857 - recall_7: 0.0061\n",
      "Epoch 2/10\n",
      "215/215 - 1s - loss: 0.6251 - accuracy: 0.6697 - precision_7: 0.9110 - recall_7: 0.2570\n",
      "Epoch 3/10\n",
      "215/215 - 1s - loss: 0.5180 - accuracy: 0.7963 - precision_7: 0.8591 - recall_7: 0.6293\n",
      "Epoch 4/10\n",
      "215/215 - 1s - loss: 0.4241 - accuracy: 0.8349 - precision_7: 0.8552 - recall_7: 0.7417\n",
      "Epoch 5/10\n",
      "215/215 - 1s - loss: 0.3584 - accuracy: 0.8573 - precision_7: 0.8655 - recall_7: 0.7909\n",
      "Epoch 6/10\n",
      "215/215 - 1s - loss: 0.3085 - accuracy: 0.8764 - precision_7: 0.8766 - recall_7: 0.8293\n",
      "Epoch 7/10\n",
      "215/215 - 1s - loss: 0.2671 - accuracy: 0.8968 - precision_7: 0.8949 - recall_7: 0.8612\n",
      "Epoch 8/10\n",
      "215/215 - 1s - loss: 0.2336 - accuracy: 0.9127 - precision_7: 0.9079 - recall_7: 0.8870\n",
      "Epoch 9/10\n",
      "215/215 - 1s - loss: 0.2053 - accuracy: 0.9219 - precision_7: 0.9179 - recall_7: 0.8988\n",
      "Epoch 10/10\n",
      "215/215 - 1s - loss: 0.1824 - accuracy: 0.9327 - precision_7: 0.9260 - recall_7: 0.9168\n",
      "215/215 - 1s - loss: 0.1587 - accuracy: 0.9445 - precision_7: 0.9415 - recall_7: 0.9287\n",
      "24/24 - 0s - loss: 0.5818 - accuracy: 0.7687 - precision_7: 0.7427 - recall_7: 0.7015\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "215/215 - 2s - loss: 0.6829 - accuracy: 0.5690 - precision_8: 0.5000 - recall_8: 0.0183\n",
      "Epoch 2/10\n",
      "215/215 - 1s - loss: 0.6349 - accuracy: 0.7091 - precision_8: 0.8023 - recall_8: 0.4314\n",
      "Epoch 3/10\n",
      "215/215 - 1s - loss: 0.5481 - accuracy: 0.7675 - precision_8: 0.8038 - recall_8: 0.6092\n",
      "Epoch 4/10\n",
      "215/215 - 1s - loss: 0.4779 - accuracy: 0.7904 - precision_8: 0.8075 - recall_8: 0.6746\n",
      "Epoch 5/10\n",
      "215/215 - 1s - loss: 0.4239 - accuracy: 0.8186 - precision_8: 0.8306 - recall_8: 0.7274\n",
      "Epoch 6/10\n",
      "215/215 - 1s - loss: 0.3793 - accuracy: 0.8374 - precision_8: 0.8347 - recall_8: 0.7765\n",
      "Epoch 7/10\n",
      "215/215 - 1s - loss: 0.3440 - accuracy: 0.8628 - precision_8: 0.8460 - recall_8: 0.8334\n",
      "Epoch 8/10\n",
      "215/215 - 1s - loss: 0.3154 - accuracy: 0.8689 - precision_8: 0.8445 - recall_8: 0.8530\n",
      "Epoch 9/10\n",
      "215/215 - 1s - loss: 0.2933 - accuracy: 0.8759 - precision_8: 0.8481 - recall_8: 0.8676\n",
      "Epoch 10/10\n",
      "215/215 - 1s - loss: 0.2759 - accuracy: 0.8790 - precision_8: 0.8453 - recall_8: 0.8805\n",
      "215/215 - 1s - loss: 0.2562 - accuracy: 0.8882 - precision_8: 0.8641 - recall_8: 0.8788\n",
      "24/24 - 0s - loss: 0.5584 - accuracy: 0.7635 - precision_8: 0.7430 - recall_8: 0.6635\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "215/215 - 2s - loss: 0.6772 - accuracy: 0.5693 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
      "Epoch 2/10\n",
      "215/215 - 1s - loss: 0.6332 - accuracy: 0.6235 - precision_9: 0.9324 - recall_9: 0.1355\n",
      "Epoch 3/10\n",
      "215/215 - 1s - loss: 0.5553 - accuracy: 0.8075 - precision_9: 0.8953 - recall_9: 0.6262\n",
      "Epoch 4/10\n",
      "215/215 - 1s - loss: 0.4638 - accuracy: 0.8475 - precision_9: 0.8773 - recall_9: 0.7509\n",
      "Epoch 5/10\n",
      "215/215 - 1s - loss: 0.3932 - accuracy: 0.8621 - precision_9: 0.8933 - recall_9: 0.7719\n",
      "Epoch 6/10\n",
      "215/215 - 1s - loss: 0.3413 - accuracy: 0.8710 - precision_9: 0.8946 - recall_9: 0.7940\n",
      "Epoch 7/10\n",
      "215/215 - 1s - loss: 0.3004 - accuracy: 0.8844 - precision_9: 0.9091 - recall_9: 0.8129\n",
      "Epoch 8/10\n",
      "215/215 - 1s - loss: 0.2666 - accuracy: 0.8936 - precision_9: 0.9155 - recall_9: 0.8295\n",
      "Epoch 9/10\n",
      "215/215 - 1s - loss: 0.2390 - accuracy: 0.9040 - precision_9: 0.9210 - recall_9: 0.8499\n",
      "Epoch 10/10\n",
      "215/215 - 1s - loss: 0.2166 - accuracy: 0.9148 - precision_9: 0.9274 - recall_9: 0.8702\n",
      "215/215 - 1s - loss: 0.1929 - accuracy: 0.9237 - precision_9: 0.9395 - recall_9: 0.8794\n",
      "24/24 - 0s - loss: 0.5547 - accuracy: 0.7556 - precision_9: 0.7190 - recall_9: 0.6875\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "215/215 - 2s - loss: 0.6731 - accuracy: 0.5687 - precision_10: 1.0000 - recall_10: 6.7636e-04\n",
      "Epoch 2/10\n",
      "215/215 - 1s - loss: 0.6101 - accuracy: 0.6875 - precision_10: 0.9080 - recall_10: 0.3071\n",
      "Epoch 3/10\n",
      "215/215 - 1s - loss: 0.5180 - accuracy: 0.8149 - precision_10: 0.8758 - recall_10: 0.6655\n",
      "Epoch 4/10\n",
      "215/215 - 1s - loss: 0.4386 - accuracy: 0.8390 - precision_10: 0.8787 - recall_10: 0.7274\n",
      "Epoch 5/10\n",
      "215/215 - 1s - loss: 0.3774 - accuracy: 0.8551 - precision_10: 0.8815 - recall_10: 0.7673\n",
      "Epoch 6/10\n",
      "215/215 - 1s - loss: 0.3284 - accuracy: 0.8777 - precision_10: 0.8952 - recall_10: 0.8116\n",
      "Epoch 7/10\n",
      "215/215 - 1s - loss: 0.2885 - accuracy: 0.8929 - precision_10: 0.9070 - recall_10: 0.8377\n",
      "Epoch 8/10\n",
      "215/215 - 1s - loss: 0.2545 - accuracy: 0.9072 - precision_10: 0.9173 - recall_10: 0.8627\n",
      "Epoch 9/10\n",
      "215/215 - 1s - loss: 0.2257 - accuracy: 0.9205 - precision_10: 0.9298 - recall_10: 0.8823\n",
      "Epoch 10/10\n",
      "215/215 - 1s - loss: 0.2026 - accuracy: 0.9288 - precision_10: 0.9379 - recall_10: 0.8941\n",
      "215/215 - 1s - loss: 0.1778 - accuracy: 0.9409 - precision_10: 0.9525 - recall_10: 0.9084\n",
      "24/24 - 0s - loss: 0.5400 - accuracy: 0.7582 - precision_10: 0.7124 - recall_10: 0.6943\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "scores = []\n",
    "models = []\n",
    "\n",
    "i = 1\n",
    "for fold_train_indices, fold_val_indices in kfold.split(train_text, train_label):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "    fold_train_text = train_text[fold_train_indices]\n",
    "    fold_train_label = train_label[fold_train_indices]\n",
    "    fold_val_text = train_text[fold_val_indices]\n",
    "    fold_val_label = train_label[fold_val_indices]\n",
    "\n",
    "    model = build_model()\n",
    "    model.fit(fold_train_text, fold_train_label, epochs=epochs, verbose=2)\n",
    "    models.append(model)\n",
    "\n",
    "    fold_train_score = model.evaluate(fold_train_text, fold_train_label, verbose=2)\n",
    "    fold_val_score = model.evaluate(fold_val_text, fold_val_label, verbose=2)\n",
    "    scores.append({'train': fold_train_score, 'val': fold_val_score})\n",
    "\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We compute the F1-score:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "for fold_scores in scores:\n",
    "    for subset in ['train', 'val']:\n",
    "        precision = fold_scores[subset][2]\n",
    "        recall = fold_scores[subset][3]\n",
    "        f1_score = 2/(1/precision + 1/recall)\n",
    "        fold_scores[subset].append(f1_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And print a detailed summary of the scores:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Average scores for all folds - Train\n",
      "> Loss: 0.1934 -  Accuracy: 0.9319 - Precision: 0.9336 - Recall: 0.9065 - F1-score: 0.9197\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds - Validation\n",
      "> Loss: 0.561 -  Accuracy: 0.7566 - Precision: 0.7318 - Recall: 0.6856 - F1-score: 0.7075\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Train\n",
      ">>> Loss: 0.228 - Accuracy: 0.9197 - Precision: 0.9325 - Recall: 0.875 - F1-score: 0.9029\n",
      "> Fold 1 - Validation\n",
      ">>> Loss: 0.5972 - Accuracy: 0.7178 - Precision: 0.6991 - Recall: 0.6771 - F1-score: 0.688\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Train\n",
      ">>> Loss: 0.2663 - Accuracy: 0.9146 - Precision: 0.8972 - Recall: 0.9049 - F1-score: 0.901\n",
      "> Fold 2 - Validation\n",
      ">>> Loss: 0.6298 - Accuracy: 0.7362 - Precision: 0.7182 - Recall: 0.6372 - F1-score: 0.6753\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Train\n",
      ">>> Loss: 0.1706 - Accuracy: 0.9458 - Precision: 0.9541 - Recall: 0.9182 - F1-score: 0.9358\n",
      "> Fold 3 - Validation\n",
      ">>> Loss: 0.5246 - Accuracy: 0.7612 - Precision: 0.7256 - Recall: 0.7077 - F1-score: 0.7165\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Train\n",
      ">>> Loss: 0.16 - Accuracy: 0.9459 - Precision: 0.9521 - Recall: 0.92 - F1-score: 0.9358\n",
      "> Fold 4 - Validation\n",
      ">>> Loss: 0.4711 - Accuracy: 0.7898 - Precision: 0.7739 - Recall: 0.7319 - F1-score: 0.7523\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Train\n",
      ">>> Loss: 0.1395 - Accuracy: 0.9596 - Precision: 0.9649 - Recall: 0.9404 - F1-score: 0.9525\n",
      "> Fold 5 - Validation\n",
      ">>> Loss: 0.5887 - Accuracy: 0.753 - Precision: 0.7065 - Recall: 0.693 - F1-score: 0.6997\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Train\n",
      ">>> Loss: 0.1844 - Accuracy: 0.9362 - Precision: 0.9375 - Recall: 0.9115 - F1-score: 0.9243\n",
      "> Fold 6 - Validation\n",
      ">>> Loss: 0.5636 - Accuracy: 0.7622 - Precision: 0.7774 - Recall: 0.6618 - F1-score: 0.715\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Train\n",
      ">>> Loss: 0.1587 - Accuracy: 0.9445 - Precision: 0.9415 - Recall: 0.9287 - F1-score: 0.9351\n",
      "> Fold 7 - Validation\n",
      ">>> Loss: 0.5818 - Accuracy: 0.7687 - Precision: 0.7427 - Recall: 0.7015 - F1-score: 0.7215\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Train\n",
      ">>> Loss: 0.2562 - Accuracy: 0.8882 - Precision: 0.8641 - Recall: 0.8788 - F1-score: 0.8714\n",
      "> Fold 8 - Validation\n",
      ">>> Loss: 0.5584 - Accuracy: 0.7635 - Precision: 0.743 - Recall: 0.6635 - F1-score: 0.701\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Train\n",
      ">>> Loss: 0.1929 - Accuracy: 0.9237 - Precision: 0.9395 - Recall: 0.8794 - F1-score: 0.9085\n",
      "> Fold 9 - Validation\n",
      ">>> Loss: 0.5547 - Accuracy: 0.7556 - Precision: 0.719 - Recall: 0.6875 - F1-score: 0.7029\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Train\n",
      ">>> Loss: 0.1778 - Accuracy: 0.9409 - Precision: 0.9525 - Recall: 0.9084 - F1-score: 0.9299\n",
      "> Fold 10 - Validation\n",
      ">>> Loss: 0.54 - Accuracy: 0.7582 - Precision: 0.7124 - Recall: 0.6943 - F1-score: 0.7032\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds - Train')\n",
    "print(f'> Loss: {round(np.mean([fold_score[\"train\"][0] for fold_score in scores]), 4)} -  Accuracy: {round(np.mean([fold_score[\"train\"][1] for fold_score in scores]), 4)} - Precision: {round(np.mean([fold_score[\"train\"][2] for fold_score in scores]), 4)} - Recall: {round(np.mean([fold_score[\"train\"][3] for fold_score in scores]), 4)} - F1-score: {round(np.mean([fold_score[\"train\"][4] for fold_score in scores]), 4)}')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds - Validation')\n",
    "print(f'> Loss: {round(np.mean([fold_score[\"val\"][0] for fold_score in scores]), 4)} -  Accuracy: {round(np.mean([fold_score[\"val\"][1] for fold_score in scores]), 4)} - Precision: {round(np.mean([fold_score[\"val\"][2] for fold_score in scores]), 4)} - Recall: {round(np.mean([fold_score[\"val\"][3] for fold_score in scores]), 4)} - F1-score: {round(np.mean([fold_score[\"val\"][4] for fold_score in scores]), 4)}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "i = 1\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for fold_scores in scores:\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i} - Train')\n",
    "    print(f'>>> Loss: {round(fold_scores[\"train\"][0], 4)} - Accuracy: {round(fold_scores[\"train\"][1], 4)} - Precision: {round(fold_scores[\"train\"][2], 4)} - Recall: {round(fold_scores[\"train\"][3], 4)} - F1-score: {round(fold_scores[\"train\"][4], 4)}')\n",
    "    print(f'> Fold {i} - Validation')\n",
    "    print(f'>>> Loss: {round(fold_scores[\"val\"][0], 4)} - Accuracy: {round(fold_scores[\"val\"][1], 4)} - Precision: {round(fold_scores[\"val\"][2], 4)} - Recall: {round(fold_scores[\"val\"][3], 4)} - F1-score: {round(fold_scores[\"val\"][4], 4)}')\n",
    "    i += 1\n",
    "print('------------------------------------------------------------------------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Submission\n",
    "\n",
    "We take the model and train it with all the available data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "238/238 - 2s - loss: 0.6718 - accuracy: 0.5801 - precision_11: 0.7937 - recall_11: 0.0306\n",
      "Epoch 2/10\n",
      "238/238 - 1s - loss: 0.5869 - accuracy: 0.7315 - precision_11: 0.8476 - recall_11: 0.4574\n",
      "Epoch 3/10\n",
      "238/238 - 1s - loss: 0.4838 - accuracy: 0.8065 - precision_11: 0.8426 - recall_11: 0.6759\n",
      "Epoch 4/10\n",
      "238/238 - 1s - loss: 0.4141 - accuracy: 0.8332 - precision_11: 0.8529 - recall_11: 0.7392\n",
      "Epoch 5/10\n",
      "238/238 - 1s - loss: 0.3611 - accuracy: 0.8508 - precision_11: 0.8545 - recall_11: 0.7866\n",
      "Epoch 6/10\n",
      "238/238 - 1s - loss: 0.3149 - accuracy: 0.8684 - precision_11: 0.8728 - recall_11: 0.8120\n",
      "Epoch 7/10\n",
      "238/238 - 1s - loss: 0.2764 - accuracy: 0.8865 - precision_11: 0.8886 - recall_11: 0.8413\n",
      "Epoch 8/10\n",
      "238/238 - 1s - loss: 0.2448 - accuracy: 0.9049 - precision_11: 0.9036 - recall_11: 0.8716\n",
      "Epoch 9/10\n",
      "238/238 - 1s - loss: 0.2186 - accuracy: 0.9141 - precision_11: 0.9134 - recall_11: 0.8838\n",
      "Epoch 10/10\n",
      "238/238 - 1s - loss: 0.1975 - accuracy: 0.9205 - precision_11: 0.9210 - recall_11: 0.8915\n",
      "238/238 - 1s - loss: 0.1746 - accuracy: 0.9324 - precision_11: 0.9460 - recall_11: 0.8936\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.17462129890918732,\n 0.9323525428771973,\n 0.9459546804428101,\n 0.8936105370521545]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(train_text, train_label, epochs=epochs, verbose=2)\n",
    "\n",
    "model.evaluate(train_text, train_label, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We generate the predictions for the test set:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, ..., 0, 1, 1])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = model.predict(test_text)\n",
    "test_pred = np.round(test_pred).flatten().astype('int')\n",
    "\n",
    "test_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And we save the predictions into a csv file ready for submission:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "output = pd.DataFrame({'id': test_data['id'], 'target': test_pred})\n",
    "output.to_csv('predictions/nnets.csv', index=False)\n",
    "print(\"Submission successfully saved!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2021-09-13T15:13:20.767477Z",
     "iopub.execute_input": "2021-09-13T15:13:20.767825Z",
     "iopub.status.idle": "2021-09-13T15:13:20.800558Z",
     "shell.execute_reply.started": "2021-09-13T15:13:20.767795Z",
     "shell.execute_reply": "2021-09-13T15:13:20.799077Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission successfully saved!\n"
     ]
    }
   ]
  }
 ]
}