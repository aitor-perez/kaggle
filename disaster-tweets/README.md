## NLP with disaster tweets
Kaggle challenge: https://www.kaggle.com/c/nlp-getting-started

#### 01-ridge-regression
Solution with a Ridge Regression approach based on [this](https://www.kaggle.com/philculliton/nlp-getting-started-tutorial) notebook.

#### 02-mnbayes-logreg
Solution using Multinomial Naive Bayes and Logistic Regression approaches, based on [this](https://www.kaggle.com/faressayah/natural-language-processing-nlp-for-beginners) notebook.

#### 03-nnets-scikit
Solution using Neural Networks, using the **MLPClassifier** from *scikit-learn*.

#### 04-nnets-keras
Solutions using Neural Networks, using the library *keras* from *tensorflow*. There are three attempts:
1. [01-base](04-nnets-keras/01-base/base.ipynb): We establish a fixed architecture with two convolutional layers followed by a dense layer.
2. [02-simple](04-nnets-keras/02-simple/simple.ipynb): We establish a simple, fixed architecture with just one dense layer.
3. [03-genetic](04-nnets-keras/03-genetic/genetic.ipynb): We establish a fixed architecture with two convolutional layers followed by a dense layer, and we tune the hyperparameters using a genetic approach. **We encourage the reader to have a look at this notebook.**
